{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetching Cropped GOES16 Training Samples\n",
    "\n",
    "Now we have all of the pieces to use the IBTrACS data to crop a GOES16 image around the tropical cyclone. To overcome the issue of nighttime images, we'll use band 7 of the ABI. This band is the shortwave IR band, with central wavelength at 3.9 microns.\n",
    "\n",
    "Downloading all of these GOES images will take some time, but I think it would be best to have an equal proportion of positive and negative samples in the training set. Fortunately, tropical cyclones aren't outrageously large, so we can use different parts of the same GOES image for positive and negative samples. This does have the problem though of statistically favoring images from the typical hurricane season, and this may need to be addressed later.\n",
    "\n",
    "## Import Modules\n",
    "\n",
    "We start by importing any of the needed modules. Let's also avoid plotting each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "from pyproj import Proj\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Import functions I've written\n",
    "os.chdir(\"..\")\n",
    "import goes\n",
    "import ibtracs\n",
    "\n",
    "# Don't display plots or warnings in the notebook\n",
    "matplotlib.use('Agg')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Valid IBTrACS Data\n",
    "\n",
    "We've already gone through and removed any IBTrACS data that wasn't valid for our training purposes. Let's also filter out the storm's *nature*. The nature of the storm has a few options: \n",
    "* TS - storm is tropical \n",
    "* SS - Subtropical \n",
    "* ET - Extratropical \n",
    "* DS - Disturbance \n",
    "* MX - Mix of conflicting reports \n",
    "* NR - Not Reported \n",
    "* MM - Missing\n",
    "\n",
    "For now, let's just focus on the tropical storms. Lastly, create a column that we'll set to `True` as we save off the images. Also, let's only look at the year 2017 for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ibtracs.read_data('./data/ibtracs_GOES16.csv',subsetSeason=True,yearStart=2017,yearEnd=2017)\n",
    "df = df[df['NATURE']=='TS'].reset_index()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't want to run this notebook for an entire year's worth of data, as that will probably take a while. Let's subset the data even further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>SID</th>\n",
       "      <th>SEASON</th>\n",
       "      <th>NUMBER</th>\n",
       "      <th>NAME</th>\n",
       "      <th>ISO_TIME</th>\n",
       "      <th>NATURE</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>WMO_WIND</th>\n",
       "      <th>WMO_PRES</th>\n",
       "      <th>TRACK_TYPE</th>\n",
       "      <th>DIST2LAND</th>\n",
       "      <th>LANDFALL</th>\n",
       "      <th>IFLAG</th>\n",
       "      <th>STORM_SPEED</th>\n",
       "      <th>STORM_DIR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1605</th>\n",
       "      <td>2197</td>\n",
       "      <td>2017228N14314</td>\n",
       "      <td>2017</td>\n",
       "      <td>61</td>\n",
       "      <td>HARVEY</td>\n",
       "      <td>2017-08-25 03:00:00</td>\n",
       "      <td>TS</td>\n",
       "      <td>25.2924</td>\n",
       "      <td>-94.7578</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>main</td>\n",
       "      <td>243</td>\n",
       "      <td>204</td>\n",
       "      <td>P_____________</td>\n",
       "      <td>9</td>\n",
       "      <td>313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1606</th>\n",
       "      <td>2198</td>\n",
       "      <td>2017228N14314</td>\n",
       "      <td>2017</td>\n",
       "      <td>61</td>\n",
       "      <td>HARVEY</td>\n",
       "      <td>2017-08-25 06:00:00</td>\n",
       "      <td>TS</td>\n",
       "      <td>25.6000</td>\n",
       "      <td>-95.1000</td>\n",
       "      <td>90</td>\n",
       "      <td>966</td>\n",
       "      <td>main</td>\n",
       "      <td>204</td>\n",
       "      <td>170</td>\n",
       "      <td>O_____________</td>\n",
       "      <td>9</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1607</th>\n",
       "      <td>2199</td>\n",
       "      <td>2017228N14314</td>\n",
       "      <td>2017</td>\n",
       "      <td>61</td>\n",
       "      <td>HARVEY</td>\n",
       "      <td>2017-08-25 09:00:00</td>\n",
       "      <td>TS</td>\n",
       "      <td>25.9350</td>\n",
       "      <td>-95.4651</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>main</td>\n",
       "      <td>160</td>\n",
       "      <td>133</td>\n",
       "      <td>P_____________</td>\n",
       "      <td>9</td>\n",
       "      <td>318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1608</th>\n",
       "      <td>2200</td>\n",
       "      <td>2017228N14314</td>\n",
       "      <td>2017</td>\n",
       "      <td>61</td>\n",
       "      <td>HARVEY</td>\n",
       "      <td>2017-08-25 12:00:00</td>\n",
       "      <td>TS</td>\n",
       "      <td>26.3000</td>\n",
       "      <td>-95.8000</td>\n",
       "      <td>95</td>\n",
       "      <td>949</td>\n",
       "      <td>main</td>\n",
       "      <td>133</td>\n",
       "      <td>123</td>\n",
       "      <td>O_____________</td>\n",
       "      <td>9</td>\n",
       "      <td>325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1609</th>\n",
       "      <td>2201</td>\n",
       "      <td>2017228N14314</td>\n",
       "      <td>2017</td>\n",
       "      <td>61</td>\n",
       "      <td>HARVEY</td>\n",
       "      <td>2017-08-25 15:00:00</td>\n",
       "      <td>TS</td>\n",
       "      <td>26.6999</td>\n",
       "      <td>-96.0652</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>main</td>\n",
       "      <td>126</td>\n",
       "      <td>108</td>\n",
       "      <td>P_____________</td>\n",
       "      <td>9</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index            SID  SEASON  NUMBER    NAME            ISO_TIME NATURE  \\\n",
       "1605   2197  2017228N14314    2017      61  HARVEY 2017-08-25 03:00:00     TS   \n",
       "1606   2198  2017228N14314    2017      61  HARVEY 2017-08-25 06:00:00     TS   \n",
       "1607   2199  2017228N14314    2017      61  HARVEY 2017-08-25 09:00:00     TS   \n",
       "1608   2200  2017228N14314    2017      61  HARVEY 2017-08-25 12:00:00     TS   \n",
       "1609   2201  2017228N14314    2017      61  HARVEY 2017-08-25 15:00:00     TS   \n",
       "\n",
       "          LAT      LON WMO_WIND WMO_PRES TRACK_TYPE  DIST2LAND LANDFALL  \\\n",
       "1605  25.2924 -94.7578                         main        243      204   \n",
       "1606  25.6000 -95.1000       90      966       main        204      170   \n",
       "1607  25.9350 -95.4651                         main        160      133   \n",
       "1608  26.3000 -95.8000       95      949       main        133      123   \n",
       "1609  26.6999 -96.0652                         main        126      108   \n",
       "\n",
       "               IFLAG  STORM_SPEED  STORM_DIR  \n",
       "1605  P_____________            9        313  \n",
       "1606  O_____________            9        315  \n",
       "1607  P_____________            9        318  \n",
       "1608  O_____________            9        325  \n",
       "1609  P_____________            9        331  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[(df['ISO_TIME'] > datetime.datetime(2017,8,25)) & (df['ISO_TIME'] < datetime.datetime(2017,8,26))].copy()\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Custom Functions\n",
    "\n",
    "These are just quick functions to save the image centered about the specified location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(ds,xInd,yInd,buffer,myDPI,figPath):\n",
    "    \n",
    "    '''From a GOES image, crop an image centered around [yInd,xInd] of size 2*buffer by 2*buffer'''\n",
    "    \n",
    "    f = plt.figure(frameon=False)\n",
    "    f.set_size_inches(buffer*2/myDPI,buffer*2/myDPI)\n",
    "    plt.imshow(ds.Rad[yInd-buffer:yInd+buffer,xInd-buffer:xInd+buffer],cmap='gray_r');\n",
    "    plt.axis('off');\n",
    "    plt.savefig(figPath, facecolor='w', dpi=220, edgecolor='w', bbox_inches='tight', pad_inches=0);\n",
    "    f.clear();\n",
    "    plt.close(f);\n",
    "    del(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop Training Examples\n",
    "\n",
    "Now let's loop through the dataframe observations and save off cropped examples as positive or negative training samples. First, we get all of the unique times in the data frame, and for each unique time, we find all of the IBTrACS observations that match that time. Then, we grab the image associated with that time and crop out all of the IBTrACS observations by some set buffer size about the central IBTrACS location. We then identify the pixels we saved off so that we can keep track of what pixels are free to take negative samples from in the future. Once we've done all of the positive training samples from the IBTrACS unique time for an image, we then randomly select a pixel location, test if that proposed cropped image overlaps with previously taken images, and then save the image if it doesn't overlap with other samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out a log file\n",
    "logFile = open(\"training.log\",'w')\n",
    "\n",
    "# Get the starting time\n",
    "tic = time.perf_counter()\n",
    "count = 0\n",
    "\n",
    "# Set the buffer (in pixels) size\n",
    "myDPI = 166\n",
    "buffer = int(myDPI*1.5)\n",
    "\n",
    "# Loop through all of the dates in the IBTrACS dataframe\n",
    "for date in df['ISO_TIME'].unique():\n",
    "    \n",
    "    # Update log file\n",
    "    logFile.write(\"Date: \"+str(date)+\"\\n\")\n",
    "\n",
    "    # Convert the numpy.datetime64 object into a datetime object\n",
    "    dt = datetime.datetime.fromisoformat(str(date)[:-3])\n",
    "\n",
    "    # Update log file\n",
    "    logFile.write(\"\\tDownloading imagery\\n\")\n",
    "        \n",
    "    try:\n",
    "\n",
    "        # Get the image for the specified date\n",
    "        ds = goes.download_data(date=dt,credPath=\"secrets.csv\",bucketName=\"noaa-goes16\",product='ABI-L1b-RadF',band=13)\n",
    "\n",
    "        # Update log file\n",
    "        logFile.write(\"\\tProjecting data\\n\")\n",
    "\n",
    "        # Get dataset projection data\n",
    "        satHeight = ds.goes_imager_projection.perspective_point_height\n",
    "        satLon = ds.goes_imager_projection.longitude_of_projection_origin\n",
    "        satSweep = ds.goes_imager_projection.sweep_angle_axis\n",
    "        majorMinorAxes = (ds.goes_imager_projection.semi_major_axis,ds.goes_imager_projection.semi_minor_axis)\n",
    "\n",
    "        # The projection x and y coordinates equals the scanning angle (in radians) multiplied by the satellite height\n",
    "        x = ds.variables['x'][:] * satHeight\n",
    "        y = ds.variables['y'][:] * satHeight\n",
    "\n",
    "        # Create an array of ones for the negative training samples\n",
    "        nx, ny = ds.Rad.shape\n",
    "        free = np.ones((ny,nx))\n",
    "\n",
    "        # Create a pyproj geostationary map object\n",
    "        p = Proj(proj='geos', h=satHeight, lon_0=satLon, sweep=satSweep)\n",
    "\n",
    "        # Get the subset of the dataframe that matches this date\n",
    "        dfSubset = df[df['ISO_TIME'] == date]\n",
    "        indices = dfSubset.index.values\n",
    "\n",
    "        # Update log file\n",
    "        logFile.write(\"\\tSaving cropped images\\n\")\n",
    "\n",
    "        # Loop through all of the subset dataframe rows:\n",
    "        for i in indices:\n",
    "\n",
    "            # Get the current row\n",
    "            row = dfSubset[dfSubset.index==i]\n",
    "\n",
    "            # Get the latitudes/longitudes of the track data\n",
    "            trackLat = float(row['LAT'])\n",
    "            trackLon = float(row['LON'])\n",
    "\n",
    "            # Convert lon/lat to x/y\n",
    "            trackX,trackY = p(trackLon,trackLat)\n",
    "\n",
    "            # Get the closest point to the IBTrACS data\n",
    "            xInd = np.nanargmin(abs(x-trackX))\n",
    "            yInd = np.nanargmin(abs(y-trackY))\n",
    "\n",
    "            # Set the figure file name\n",
    "            figPart = dt.strftime(\"%Y%m%d_%HZ\")+f'_{xInd:05.0f}_{yInd:05.0f}_{buffer}'\n",
    "            figPath = f'./training-data/images/positive/{figPart}_cropped.png'\n",
    "\n",
    "            # Save the cropped image\n",
    "            crop_image(ds,xInd,yInd,buffer,myDPI,figPath)\n",
    "\n",
    "            # Mark these pixels as containing a positive sample\n",
    "            free[yInd-buffer:yInd+buffer,xInd-buffer:xInd+buffer] = 0\n",
    "\n",
    "        # Now go find some random negative samples that don't overlap with locations where free == 0\n",
    "        negativeCount = 0\n",
    "        maxAttemptCount = 5*len(indices)\n",
    "        attemptCount = 0\n",
    "        while negativeCount < len(indices):\n",
    "\n",
    "            # Get a random location on the image\n",
    "            xInd = np.random.randint(buffer,nx-buffer,size=1)[0]\n",
    "            yInd = np.random.randint(buffer,ny-buffer,size=1)[0]\n",
    "\n",
    "            # Check that it doesn't overlap with previous images\n",
    "            if (free[yInd-buffer:yInd+buffer,xInd-buffer:xInd+buffer] == 1).all():\n",
    "\n",
    "                # Set the figure file name\n",
    "                figPart = dt.strftime(\"%Y%m%d_%HZ\")+f'_{xInd:05.0f}_{yInd:05.0f}_{buffer}'\n",
    "                figPath = f'./training-data/images/negative/{figPart}_cropped.png'\n",
    "\n",
    "                # Save the cropped image\n",
    "                crop_image(ds,xInd,yInd,buffer,myDPI,figPath)\n",
    "\n",
    "                # Also mark these pixels, since we have a sample already taken from them\n",
    "                free[yInd-buffer:yInd+buffer,xInd-buffer:xInd+buffer] = 0\n",
    "\n",
    "                # Advance the count of negative training sample images obtained\n",
    "                negativeCount = negativeCount + 1\n",
    "\n",
    "            # Advance the count of attempts and break if it has been going for too long\n",
    "            attemptCount = attemptCount + 1\n",
    "            if attemptCount > maxAttemptCount:\n",
    "                break\n",
    "\n",
    "        # Delete the dataset to save memory\n",
    "        del(ds)\n",
    "\n",
    "    except:\n",
    "        logFile.write(\"\\tError saving image\\n\")\n",
    "        \n",
    "# Get the ending time\n",
    "toc = time.perf_counter()\n",
    "\n",
    "# Close the logfile and write out the total time\n",
    "logFile.write(\"\\n\\n Total time taken: \"+str(toc-tic))\n",
    "logFile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
